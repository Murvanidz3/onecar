import os
import uvicorn
from curl_cffi import requests as cffi_requests
from bs4 import BeautifulSoup
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
import re

app = FastAPI()

app.mount("/static", StaticFiles(directory="static"), name="static")

class VinRequest(BaseModel):
    vin: str

def scrape_carfast(vin):
    try:
        # Carfast-áƒ˜áƒ¡ áƒ«áƒ”áƒ‘áƒœáƒ˜áƒ¡ áƒšáƒ˜áƒœáƒ™áƒ˜
        search_url = f"https://carfast.express/en/cars/buy_report?vin={vin}"
        print(f"ğŸ” Searching Carfast: {search_url}")
        
        # áƒ•áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ— Chrome-áƒ˜áƒ¡ áƒ˜áƒ›áƒ˜áƒ¢áƒáƒªáƒ˜áƒáƒ¡
        response = cffi_requests.get(
            search_url, 
            impersonate="chrome120",
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept-Language": "en-US,en;q=0.9"
            }
        )
        
        if response.status_code != 200:
            return {"error": f"Carfast Error: {response.status_code}"}

        soup = BeautifulSoup(response.content, 'html.parser')
        
        data = {
            "title": "áƒœáƒáƒáƒáƒ•áƒœáƒ˜áƒ!",
            "images": [],
            "info": {}
        }

        # 1. áƒ«áƒ˜áƒ áƒ˜áƒ—áƒáƒ“áƒ˜ áƒ¤áƒáƒ¢áƒ (Carfast-áƒ–áƒ” áƒ®áƒ¨áƒ˜áƒ áƒáƒ“ áƒ›áƒ®áƒáƒšáƒáƒ“ 1 áƒ¤áƒáƒ¢áƒ áƒ©áƒáƒœáƒ¡ áƒ£áƒ¤áƒáƒ¡áƒáƒ“)
        # áƒ•áƒ”áƒ«áƒ”áƒ‘áƒ— áƒ¡áƒ£áƒ áƒáƒ—áƒ¡ 'car-photo' áƒ™áƒšáƒáƒ¡áƒ¨áƒ˜ áƒáƒœ áƒ›áƒ¡áƒ’áƒáƒ•áƒ¡áƒ¨áƒ˜
        main_img = soup.find('img', class_='car-card__img') # áƒ¡áƒáƒ•áƒáƒ áƒáƒ£áƒ“áƒ áƒ™áƒšáƒáƒ¡áƒ˜
        
        if not main_img:
            # áƒ•áƒªáƒáƒ“áƒáƒ— áƒ£áƒ¤áƒ áƒ áƒ–áƒáƒ’áƒáƒ“áƒ˜ áƒ«áƒ”áƒ‘áƒœáƒ
            images = soup.find_all('img')
            for img in images:
                src = img.get('src', '')
                # Carfast-áƒ˜áƒ¡ áƒ¡áƒ£áƒ áƒáƒ—áƒ”áƒ‘áƒ˜ áƒ®áƒ¨áƒ˜áƒ áƒáƒ“ "photos" áƒáƒœ "images" áƒ¡áƒáƒ¥áƒáƒ¦áƒáƒšáƒ“áƒ”áƒ¨áƒ˜áƒ
                if '/photos/' in src or 'blob:' not in src and src.startswith('http'):
                    if 'logo' not in src and 'icon' not in src:
                        data['images'].append(src)
                        break # áƒáƒ˜áƒ áƒ•áƒ”áƒšáƒ˜áƒ•áƒ” áƒ áƒ”áƒáƒšáƒ£áƒ  áƒ¤áƒáƒ¢áƒáƒ¡ áƒ•áƒ˜áƒ¦áƒ”áƒ‘áƒ—
        else:
            src = main_img.get('src')
            if src: data['images'].append(src)

        # 2. áƒ˜áƒœáƒ¤áƒáƒ áƒ›áƒáƒªáƒ˜áƒ˜áƒ¡ áƒáƒ›áƒáƒ¦áƒ”áƒ‘áƒ (áƒªáƒ®áƒ áƒ˜áƒšáƒ˜áƒ“áƒáƒœ)
        # áƒ•áƒ”áƒ«áƒ”áƒ‘áƒ— "VIN", "Model", "Engine"
        info_blocks = soup.find_all('div', class_='car-card__row') # áƒ¡áƒáƒ•áƒáƒ áƒáƒ£áƒ“áƒ áƒ¡áƒ¢áƒ áƒ£áƒ¥áƒ¢áƒ£áƒ áƒ
        
        # áƒ—áƒ£ áƒ™áƒšáƒáƒ¡áƒ”áƒ‘áƒ˜ áƒ¨áƒ”áƒ˜áƒªáƒ•áƒáƒšáƒ, áƒ•áƒ”áƒ«áƒ”áƒ‘áƒ— áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ—
        text_content = soup.get_text()
        
        model_match = re.search(r'Model\s+([A-Za-z0-9\s]+)', text_content)
        engine_match = re.search(r'Engine\s+([A-Za-z0-9\.\s]+)', text_content)
        
        if model_match:
            data['title'] = model_match.group(1).strip()
        else:
            # áƒ¡áƒáƒ—áƒáƒ£áƒ áƒ˜áƒ¡ áƒáƒšáƒ¢áƒ”áƒ áƒœáƒáƒ¢áƒ˜áƒ£áƒšáƒ˜ áƒ«áƒ”áƒ‘áƒœáƒ
            h1 = soup.find('h1')
            if h1: data['title'] = h1.get_text(strip=True)

        if engine_match:
            data['info']['engine'] = engine_match.group(1).strip()

        # áƒ—áƒ£ áƒ¤áƒáƒ¢áƒ áƒ•áƒ”áƒ  áƒ•áƒ˜áƒáƒáƒ•áƒ”áƒ—, áƒ”.áƒ˜. áƒáƒ áƒáƒ¤áƒ”áƒ áƒ˜ áƒ©áƒáƒœáƒ¡
        if not data['images']:
            # áƒ™áƒ˜áƒ“áƒ”áƒ• áƒ”áƒ áƒ—áƒ˜ áƒªáƒ“áƒ: áƒ•áƒ”áƒ«áƒ”áƒ‘áƒ— background-image-áƒ¡
            divs = soup.find_all('div', style=True)
            for div in divs:
                style = div['style']
                if 'background-image' in style and 'url' in style:
                    url_match = re.search(r'url\([\'"]?(.*?)[\'"]?\)', style)
                    if url_match:
                        img_url = url_match.group(1)
                        if 'car' in img_url or 'photo' in img_url:
                            data['images'].append(img_url)
                            break

        if not data['images']:
             return {"error": "áƒ¤áƒáƒ¢áƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ (áƒ¨áƒ”áƒ¡áƒáƒ«áƒšáƒáƒ áƒ¤áƒáƒ¡áƒ˜áƒáƒœáƒ˜áƒ áƒáƒœ VIN áƒáƒ áƒáƒ¡áƒ¬áƒáƒ áƒ˜áƒ)"}

        return data

    except Exception as e:
        print(f"ğŸ”¥ Error scraping: {e}")
        return {"error": str(e)}

@app.get("/")
def read_root():
    return FileResponse('static/index.html')

@app.post("/check_vin")
def check_vin_handler(req: VinRequest):
    result = scrape_carfast(req.vin)
    return result

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)