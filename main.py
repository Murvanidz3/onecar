import os
import uvicorn
from curl_cffi import requests as cffi_requests
from bs4 import BeautifulSoup
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
import re

app = FastAPI()

app.mount("/static", StaticFiles(directory="static"), name="static")

class VinRequest(BaseModel):
    vin: str

def scrape_bidcars(vin):
    try:
        # 1. áƒ«áƒ”áƒ‘áƒœáƒ VIN áƒ™áƒáƒ“áƒ˜áƒ— Bid.cars-áƒ–áƒ”
        search_url = f"https://bid.cars/en/search/results?search-term={vin}"
        print(f"ğŸ” Searching: {search_url}")
        
        # áƒ•áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ— Chrome-áƒ˜áƒ¡ áƒ˜áƒ›áƒ˜áƒ¢áƒáƒªáƒ˜áƒáƒ¡ (áƒ“áƒáƒªáƒ•áƒ˜áƒ¡ áƒ’áƒáƒ¡áƒáƒ•áƒšáƒ”áƒšáƒáƒ“)
        response = cffi_requests.get(search_url, impersonate="chrome124")
        
        if response.status_code != 200:
            return {"error": f"áƒ•áƒ”áƒ  áƒ“áƒáƒ•áƒ£áƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ“áƒ˜ áƒ¡áƒáƒ˜áƒ¢áƒ¡ (Status: {response.status_code})"}

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # 2. áƒ•áƒ”áƒ«áƒ”áƒ‘áƒ— áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ¡ (áƒ›áƒáƒœáƒ¥áƒáƒœáƒ˜áƒ¡ áƒšáƒ˜áƒœáƒ™áƒ¡)
        car_link = None
        
        # áƒ•áƒáƒ›áƒáƒ¬áƒ›áƒ”áƒ‘áƒ—, áƒáƒ˜áƒ áƒ“áƒáƒáƒ˜áƒ  áƒ®áƒáƒ› áƒáƒ  áƒ’áƒáƒ“áƒáƒ’áƒ•áƒáƒ’áƒ“áƒ áƒ›áƒáƒœáƒ¥áƒáƒœáƒ˜áƒ¡ áƒ’áƒ•áƒ”áƒ áƒ“áƒ–áƒ”?
        if "/lot/" in response.url:
            car_link = response.url
        else:
            # áƒ—áƒ£ áƒáƒ áƒ, áƒ•áƒ”áƒ«áƒ”áƒ‘áƒ— áƒ¡áƒ˜áƒáƒ¨áƒ˜
            results = soup.find_all('a', href=True)
            for link in results:
                if "/lot/" in link['href']:
                    car_link = link['href']
                    break
        
        if not car_link:
             return {"error": "áƒ›áƒáƒœáƒ¥áƒáƒœáƒ áƒáƒ áƒ¥áƒ˜áƒ•áƒ¨áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ ğŸ¤·â€â™‚ï¸"}

        # áƒ¡áƒ áƒ£áƒšáƒ˜ áƒšáƒ˜áƒœáƒ™áƒ˜áƒ¡ áƒáƒ¬áƒ§áƒáƒ‘áƒ
        if not car_link.startswith("http"):
            full_link = f"https://bid.cars{car_link}"
        else:
            full_link = car_link

        print(f"âœ… Found Page: {full_link}")

        # 3. áƒ¨áƒ”áƒ•áƒ“áƒ˜áƒ•áƒáƒ áƒ— áƒ›áƒáƒœáƒ¥áƒáƒœáƒ˜áƒ¡ áƒ’áƒ•áƒ”áƒ áƒ“áƒ–áƒ”
        page_response = cffi_requests.get(full_link, impersonate="chrome124")
        page_soup = BeautifulSoup(page_response.content, 'html.parser')

        # 4. áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒáƒ›áƒáƒ¦áƒ”áƒ‘áƒ
        data = {
            "title": "áƒ£áƒªáƒœáƒáƒ‘áƒ˜",
            "images": [],
            "info": {}
        }

        # áƒ¡áƒáƒ—áƒáƒ£áƒ áƒ˜
        h1 = page_soup.find('h1')
        if h1: data['title'] = h1.get_text(strip=True)

        # áƒ¤áƒáƒ¢áƒáƒ”áƒ‘áƒ˜ (áƒ•áƒ”áƒ«áƒ”áƒ‘áƒ— áƒ“áƒ˜áƒ“ áƒ¡áƒ£áƒ áƒáƒ—áƒ”áƒ‘áƒ¡)
        images = []
        img_tags = page_soup.find_all('img')
        for img in img_tags:
            src = img.get('src') or img.get('data-src')
            if src and "media.bid.cars" in src and "small" not in src:
                # áƒ•áƒáƒ¡áƒ£áƒ¤áƒ—áƒáƒ•áƒ”áƒ‘áƒ— áƒšáƒ˜áƒœáƒ™áƒ¡ áƒ áƒáƒ› áƒ“áƒ˜áƒ“áƒ˜ áƒ–áƒáƒ›áƒ áƒ›áƒ˜áƒ•áƒ˜áƒ¦áƒáƒ—
                full_size = src.replace("thumbnails/", "").replace("small/", "")
                if full_size not in images:
                    images.append(full_size)
        
        # áƒ•áƒ˜áƒ¦áƒ”áƒ‘áƒ— áƒáƒ˜áƒ áƒ•áƒ”áƒš 5 áƒ¤áƒáƒ¢áƒáƒ¡
        data['images'] = images[:5]

        # áƒ¢áƒ”áƒ¥áƒœáƒ˜áƒ™áƒ£áƒ áƒ˜ áƒ˜áƒœáƒ¤áƒ (áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ“áƒáƒœ áƒáƒ›áƒáƒ¦áƒ”áƒ‘áƒ)
        info_block = page_soup.get_text()
        
        odometer = re.search(r'Odometer[:\s]+([\d,]+)', info_block)
        damage = re.search(r'Primary Damage[:\s]+([A-Za-z\s]+)', info_block)
        engine = re.search(r'Engine[:\s]+([0-9\.]+L)', info_block)

        if odometer: data['info']['odometer'] = odometer.group(1).strip()
        if damage: data['info']['damage'] = damage.group(1).strip()
        if engine: data['info']['engine'] = engine.group(1).strip()

        return data

    except Exception as e:
        print(f"ğŸ”¥ Error scraping: {e}")
        return {"error": str(e)}

@app.get("/")
def read_root():
    return FileResponse('static/index.html')

# áƒáƒ®áƒáƒšáƒ˜ áƒ”áƒœáƒ“áƒáƒáƒ˜áƒœáƒ¢áƒ˜
@app.post("/check_vin")
def check_vin_handler(req: VinRequest):
    result = scrape_bidcars(req.vin)
    return result

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)